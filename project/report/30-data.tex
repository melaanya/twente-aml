\section{Data}
\label{sec:data}
Throughout this project we make use of three datasets for housing price prediction publicly available from Kaggle competitions. We choose them under assumption that testing the GBDT models on various datasets with distinctive properties is important for reasoning about their performance in housing price prediction area. 

The first dataset we utilize is a classic but tiny Boston dataset \cite{boston1978housing} collected in 70's. It encloses 333 instances described by 13 features, only one of which is categorical in itself. Despite the modest size this dataset can still be employed as a rapid and reasonable initial step towards understanding of model's performance in regression problems.

We also adopt the Ames housing dataset \cite{de2011ames} incorporating 1460 observations and 80 explanatory variables involved in assessing home price: 43 categorical and 37 ordinal and continuous. It describes the sale of individual residential property in Ames, Iowa from 2006 to 2010 and includes much greater variety of information than the Boston dataset.

The third dataset is provided by Russian bank Sberbank \cite{sberbank2017housing} and not only includes housing specifications but also comprises macroeconomic patterns. It contains 12231 training instances each of which represented by 293 parameters with 18 categorical among them. This dataset is the most diverse among all the considered datasets which imposes a significant challenge to the models.

Comparative analysis shows that the Ames housing dataset offers the greatest variety of categorical features which are of the most interest taking into account specific CatBoost treatment towards them. The Sberbank dataset seems to be the most appealing in the sense of being true to life as it is mostly collected by the real estate companies which, on the other hand, makes it more noisy, and therefore, more demanding for model training.