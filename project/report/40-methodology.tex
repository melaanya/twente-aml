\section{Methodology}
\label{sec:methodology}

This section briefly explains the main differences of CatBoost model from the wide-spread industrial gradient boosting implementations such as scikit-learn and XGBoost. Furthermore, we discuss performed data preprocessing and the evaluating procedure that we employ.

\subsection{Model}

In our research we compare the performance of CatBoostRegressor from CatBoost library with other two existing publicly available implementations of gradient boosting algorithm for regression problems: GradientBoostingRegressor from scikit-learn and XGBoostRegressor from XGBoost. There are two fundamental key points which we consider remarkable in the CatBoost implementation: categorical feature processing and tackling the problem of bias in gradient estimations. 

Regarding the categorical features, CatBoost adopts an efficient strategy for handling them in the data which is essentially substituting the category labels with some statistics computed per category with incorporated intention of overfitting prevention. To accomplish this, it performs a random permutation of the dataset and for each example it computes average label value for the example with the same category value placed before the given one in the permutation. 
If we denote the permutation as $ \sigma = (\sigma_1, ..., \sigma_n)$, the feature vector as $ X_i = (x_{i, 1}, ..., x_{i, n})$, the label value as $Y_i$ and the prior value with its weight as $P$ and $a$ $(a > 0)$ respectively then the statistics is computed by the following formula:

$$ \frac{\sum_{j=1}^{p-1} [ x_{\sigma_j, i} = x_{\sigma_p, i}] Y_{\sigma_j} + a \cdot P}{\sum_{j=1}^{p-1} [ x_{\sigma_j, i} = x_{\sigma_p, i}] + a }. $$

Adding the prior helps reducing the noise obtained from low-frequency categories. The standard technique for choosing the prior in regression problems is to take the average label value in the dataset.

Furthermore, CatBoost suggests a principled way of mitigating the problem of biased pointwise gradient estimates by proposing the dynamic boosting approach that avoids the estimation bias at a minimal cost of the variance of the gradient estimation. Usually gradients are assessed exploiting the same data points on each iteration which introduces a bias as prevailing strategy of choosing a new estimator on the next step internally involves the knowledge of the decision made by the predecessors. This fact essentially leads to a shift from actual distribution of gradients in the feature space. To overcome this problem, for each training instance a separate model is employed which is never updated using the gradient estimate for this example. CatBoost implementation follows one relaxation of this idea which makes it feasible to employ: all these separate models share the same tree structures. Nevertheless, this optimization strategy requires much time and computational resources to be performed efficiently.

\subsection{Training}

In this project we examine the performance of CatBoostRegressor model from CatBoost in the field of housing price prediction and compare it with two other state-of-the-art GBDT implementations, namely GradientBoostingRegressor from scikit-learn and XGBoostRegressor from XGBoost. We assess the performance of these models  by applying them on three different datasets described in \cref{sec:data} without any preliminary feature selection as we do not opt for gaining the highest possible score but for analyzing models conduct when put in the same conditions.

In order to make use of GradientBoostingRegressor we first need to preprocess the data: for numerical columns we replace the missing values with the mean along each column whereas for categorical variables we perform one-hot encoding. Regarding XGBoostRegressor, we solely rely on its internal missing values treatment but repeat the procedure of binarizing the categorical variables. We do not adopt any additional feature preprocessing for CatBoostRegressor, only explicitly specify the categorical variables for their further internal processing. All the models are first trained with their default parameters which one can find in Appendix \cref{tab:default-parameters} and later tuned by employing the grid search over the predefined set of parameters which can be found in Appendix \cref{tab:grid-search-parameters}.

\subsection{Evaluation}

To evaluate the regression problem we employ the Root Mean Squared Logarithmic Error (RMSLE) as it equally penalizes the mismatches within small and huge values. Let $p_i$ be the predicted values and $a_i$ the actual values, then RMSLE is computed as follows:

$$ RMSLE = \sqrt[]{\frac{1}{N}\sum_{n = 1}^N (\log(p_i + 1) - \log(a_i + 1))^2}. $$

In order to assess the performance of the discussed algorithms and execute the grid search over the predefined set of parameters, we employ 5-fold cross validation. Throughout this research, the training time is also of great interest for us, and thus, we measure it 3 times in a row and report the average.



