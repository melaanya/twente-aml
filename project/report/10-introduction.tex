\section{Introduction}
\label{sec:introduction}

Gradient boosting is an ensemble machine learning algorithm that results in a strong prediction model based on several weak estimators e.g. decision trees. Gradient boosted decision trees (GBDT) are built sequentially so as each new tree attempts to correct the errors made by the predecessors and cover the discrepancy between the target function and the current prediction. This ensemble technique has been both theoretically and empirically proven to be useful in various machine learning problems and is widely employed in various machine learning competitions. There are several widely used implementations of this algorithm such as XGBoost, GradientBoosting from sklearn, LightGBM etc. XGBoost in particular has been key to a lot of winning models in Kaggle competitions due to its speed and performance. A recently appeared implementation of this algorithm is created by the Russian company Yandex and is called CatBoost due to its special treatment of categorical features.

CatBoost is an open-source gradient boosting library which, according to Yandex, offers fast inference, categorical feature support, and improved prediction accuracy. It is claimed that CatBoost outperforms existing implementations of GDBT in classification tasks on multiple benchmarks whereas there is no information about its performance in regression problems. The main goal of this project is to assess the performance of CatBoost on the regression task of housing price prediction and compare it with the performances of two other state-of-the art GBDT libraries, namely XGBoost and sklearn.

Apart from being a real-world application of GDBT, housing market prediction is a good example of regression problem in which the model predicts a continuous variable. In the scope of this project we make use of three datasets: Boston Housing \cite{boston1978housing}, the Ames Housing \cite{de2011ames} and Sberbank Russian Housing Market \cite{sberbank2017housing} datasets, each with vastly different characteristics.

In this paper BRIEFLY RESULTS

The remainder of the paper is structured as follows. We discuss the related work in \cref{sec:related-work}. \cref{sec:data} describes the data used for training and evaluation. \cref{sec:methodology} addresses the methodology of our research. In \cref{sec:results}, we present experimental results whereas in \cref{sec:discussion} we reflect on the performed investigation. We conclude this research and present some ideas for future work in \cref{sec:results}.