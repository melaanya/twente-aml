\section{Conclusion}
\label{sec:conclusion}

In this research we investigate the applicability of a recently appeared implementation of GDBTs CatBoost with intricate categorical feature preprocessing and a new advanced approach to fighting the bias in gradient estimation. Additionally, we employ two other competitive GBDT implementations and compare their performance on three different datasets for housing price prediction. During the research, we found out that CatBoost outperforms two models only on Boston dataset with the smallest number of both features and training instances while still conceding to other models in more realistic Ames and Sberbank datasets. Further analysis shows CatBoost's apparent preference towards the categorical variables when building the estimators which does not always result in score improvements.

In case we would have more time and additional resources, we would firstly employ the GPU version of the CatBoost library as its long training time when executing on CPU prevented us from performing more extensive grid search. With more experiments conducted and sensible parameter tuning we could gain additional score improvement. Also it might be beneficial for the performance of all three models to explore smaller feature subsets as for real-life datasets the feature space is utterly sparse which makes the problem excessively perplex and ambiguate. Finally, it seems appealing to extend this research to other regression tasks and assess the performance of CatBoost when applied to them in order to provide more general conclusions about library's qualities.